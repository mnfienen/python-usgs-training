{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in the daily values for the entire history of Lee's Ferry and the Grand Canyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_num = {'Lees Ferry':'09380000',\"Grand Canyon\": '09402500'}\n",
    "urls = dict()\n",
    "for ckey,cval in site_num.items():\n",
    "    dv_url = 'http://waterservices.usgs.gov/nwis/dv/?format=rdb'\n",
    "    dv_url += '&sites={0}'.format(cval)\n",
    "    #dv_url += '&startDT=2010-01-01'\n",
    "    dv_url += '&startDT=1880-01-01'\n",
    "    #dv_url += '&endDT=2018-01-17'\n",
    "    dv_url += '&parameterCd=00060'\n",
    "    print(dv_url)\n",
    "    urls[ckey] = dv_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ckey,cval in urls.items():\n",
    "    print ('reading data for {0}'.format(ckey))\n",
    "    dv_file = requests.get(cval)\n",
    "\n",
    "    with open(os.path.join('data','pandas','{0}.dat'.format(ckey)), 'w') as ofp:\n",
    "        for carp in dv_file:\n",
    "            ofp.write(carp.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NWISfilename = os.path.join('data','pandas','Lees Ferry.dat')\n",
    "reconnoiter = open(NWISfilename, 'r').readlines()\n",
    "for i in np.arange(60):\n",
    "    print (reconnoiter[i].rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numhash = 0 #let's use the as the counter\n",
    "for line in reconnoiter:\n",
    "    if line.startswith('#'):\n",
    "        numhash +=1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print (numhash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckey in site_num.keys():\n",
    "    recon = open(os.path.join('data','pandas','{0}.dat'.format(ckey))).readlines()\n",
    "    numhash = 0 #let's use the as the counter\n",
    "    for line in recon:\n",
    "        if line.startswith('#'):\n",
    "            numhash +=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print (numhash)\n",
    "    colnames = recon[numhash].rstrip().split()\n",
    "    colnames[3] = 'Q'\n",
    "    \n",
    "    df_dict[ckey] = pd.read_csv(os.path.join('data','pandas','{0}.dat'.format(ckey)),\n",
    "                          sep='\\t',\n",
    "                          skiprows = numhash+2,\n",
    "                          names = colnames,\n",
    "                          parse_dates = True,\n",
    "                          index_col = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['Grand Canyon'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's drop all the columns we don't need \n",
    "## NB --> what's up with `inplace=True`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckey, nwis_df in df_dict.items(): \n",
    "    nwis_df.drop((['site_no']),axis=1,inplace=True)\n",
    "\n",
    "    # we can use a list comprehension\n",
    "    nwis_df.drop([i for i in nwis_df.columns if i.endswith('cd')], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at things by water year\n",
    "First, we can make a couple new columns, one for year, and one for water year.\n",
    "\n",
    "How can we group by water year? Not a very easy Google Kung Fu exercise at first, but what about \"Fiscal Year\"?\n",
    "Google \"Pandas group by fiscal year\"\n",
    "http://stackoverflow.com/questions/26341272/using-groupby-on-pandas-dataframe-to-group-by-financial-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckey, nwis_df in df_dict.items(): \n",
    "    #make water year by shifting forward the number of days in Oct., Nov., and Dec.\n",
    "    # NOTE --> shifting by months is less precise\n",
    "    nwis_df['water_year'] = nwis_df.index.shift(30+31+31,freq='d').year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So now we can add columns with some unit conversions\n",
    "\n",
    "## units are $\\frac{ft^3}{s}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So let's convert to cubic feet per day which we can later sum up by water year\n",
    "## $\\frac{1 ft^3}{s} \\times \\frac{60s}{min} \\times \\frac{60min}{hour} \\times \\frac{24hours}{day} \\rightarrow \\frac{ft^3}{day}$\n",
    "\n",
    "## 1 acre-foot = 43559.9 cubic feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckey, nwis_df in df_dict.items(): \n",
    "    nwis_df['Q_cfd'] = nwis_df.Q * 60 * 60 * 24\n",
    "    nwis_df['Q_af'] = nwis_df.Q_cfd / 43559.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `agg` is for aggregate - very powerful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wateryears = dict()\n",
    "for ckey, nwis_df in df_dict.items(): \n",
    "\n",
    "    wateryears[ckey] = nwis_df.groupby('water_year').agg(['count','mean','sum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wateryears['Lees Ferry'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's explore Lee's Ferry in a bit more detail\n",
    "\n",
    "## First, any missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this has a multiple index\n",
    "plt.figure(figsize=(14,4))\n",
    "wateryears['Lees Ferry']['Q','count'].plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's look at statistics to see if there are any missing days prior to 2018 (partial year)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wateryears['Lees Ferry'].loc[wateryears['Lees Ferry'].index<2018].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice! 25% are leap years (mean is 365.25), and no years have less than 365 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Colorado River Compact mandates there should be 7.5E6 Acre-feet /year\n",
    "## of flow at Lee's Ferry. Is that happening?\n",
    "https://en.wikipedia.org/wiki/Colorado_River_Compact \n",
    "\n",
    "https://www.usbr.gov/lc/region/pao/pdfiles/crcompct.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wateryears['Lees Ferry']['Q_af','sum'].loc[wateryears['Lees Ferry'].index<1963].plot()\n",
    "plt.plot([1922,1963],[7.5e6,7.5e6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wateryears['Lees Ferry']['Q_af','sum'].loc[wateryears['Lees Ferry'].index].plot()\n",
    "plt.plot([1922,wateryears['Lees Ferry'].index.max()],[7.5e6,7.5e6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some more exploration of the flow over all record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "df_dict['Lees Ferry'].Q.plot()\n",
    "plt.tight_layout()\n",
    "plt.savefig('LeesFerryOnePlot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwis_df = df_dict['Lees Ferry'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first we can apply functions to `groupby` grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "mean_Q = nwis_df.Q.groupby(nwis_df.index.year).mean()\n",
    "lower_CI = mean_Q - 2*nwis_df.Q.groupby(nwis_df.index.year).std()\n",
    "upper_CI = mean_Q + 2*nwis_df.Q.groupby(nwis_df.index.year).std()\n",
    "ax = mean_Q.plot(style='b.-')\n",
    "plt.fill_between(lower_CI.index,lower_CI,upper_CI, color='b',alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# can accomplish this in one step using `aggregate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_agg = nwis_df.Q.groupby(nwis_df.index.year).aggregate([np.min, np.mean, np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_agg(Q_agg_in):\n",
    "    Q_agg = Q_agg_in.copy()\n",
    "    Q_agg.reset_index(drop=True, inplace=True)\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    lower_CI = Q_agg['mean'] - 2*Q_agg['std']\n",
    "    upper_CI = Q_agg['mean'] + 2*Q_agg['std']\n",
    "    ax = Q_agg['mean'].plot(style='b.-')\n",
    "    plt.fill_between(Q_agg.index,lower_CI,upper_CI, color='b',alpha = 0.2)\n",
    "plot_agg(Q_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "nwis_df.Q.groupby(nwis_df.water_year).std().plot(kind='bar',rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how hard to change from annual aggregation to monthly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_agg_month = nwis_df.Q.groupby([nwis_df.index.year, nwis_df.index.month]).aggregate([np.min, np.mean, np.std])\n",
    "plot_agg(Q_agg_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## navigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwis_df.loc[nwis_df.water_year<1963].Q.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwis_df.loc[(nwis_df.water_year<1993) & (nwis_df.water_year>=1963)].Q.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwis_df = df_dict['Lees Ferry'].copy()\n",
    "nwis_df.loc[(nwis_df.index.year<1990) & (nwis_df.index.year>1948), 'Q'] *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwis_df.Q.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set them back\n",
    "nwis_df.loc[(nwis_df.index.year<1990) & (nwis_df.index.year>1948), 'Q'] /= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_fig=True\n",
    "if plot_fig:\n",
    "    with PdfPages(os.path.join('data','allyears_LeesFerry.pdf')) as outpdf:\n",
    "        for cname,cgroup in nwis_df.groupby(nwis_df.index.year):\n",
    "            print(cname)\n",
    "            plt.figure()\n",
    "            cgroup.Q.plot(title=cname)\n",
    "            plt.ylabel('cfs')\n",
    "            plt.xlabel('date')\n",
    "            plt.tight_layout()\n",
    "            outpdf.savefig()\n",
    "            plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now let's look at Lees Ferry and the Grand Canyon together\n",
    "\n",
    "## we checked out the Lees Ferry record and found no gaps, but what about Grand Canyon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this has a multiple inbdex\n",
    "plt.figure(figsize=(14,4))\n",
    "wateryears['Grand Canyon']['Q','count'].plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crumbs... looks like some year in the 1990s is short some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wateryears['Grand Canyon'].loc[wateryears['Grand Canyon'].index<2018].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wateryears['Grand Canyon']['Q','count'].loc[wateryears['Grand Canyon']['Q','count']<300].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## so what happens if we try to combine the datasets on a common time index?\n",
    "\n",
    "## let's work just with 1993-1995, making specific dataframes for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGC = df_dict['Grand Canyon'].copy()\n",
    "dfLF = df_dict['Lees Ferry'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is the GC data less complete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfGC))\n",
    "print(len(dfLF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how does this sort out with `groupby` and `aggregate`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GC_agg = dfGC.groupby(dfGC.index.year).aggregate([np.mean,np.std,'count'])\n",
    "df_GC_agg['Q','mean'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GC_agg['Q','count'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's trim down to the years around 1994 to explore how to merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGC = dfGC.loc[(dfGC.index.year>=1993) & (dfGC.index.year<=1995)]\n",
    "dfLF = dfLF.loc[(dfLF.index.year>=1993) & (dfLF.index.year<=1995)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one easy way is `pd.concat` -- note difference between `inner` and `outer` join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined=pd.concat([dfLF.Q,dfGC.Q],axis=1,join='inner')\n",
    "\n",
    "df_combined.columns = [['Q_LF', 'Q_GC']]\n",
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined=pd.concat([dfLF.Q,dfGC.Q],axis=1,join='outer')\n",
    "df_combined.columns = [['Q_LF', 'Q_GC']]\n",
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how can we fill in the missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffill=df_combined.fillna(method='ffill')\n",
    "df_ffill.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bfill=df_combined.fillna(method='bfill')\n",
    "df_bfill.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_combined.fillna(value=20000)\n",
    "df_val.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## or we can impute from the other series somehow\n",
    "\n",
    "## first just drop the NaN values for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('tmp')\n",
    "df_combined = pd.read_csv('tmp', index_col=0)\n",
    "df_dropna = df_combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropna['Qrat'] = df_dropna.Q_GC/df_dropna.Q_LF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropna.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ok, let's find the mean ratio and apply that to fill in missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rat = df_dropna.Qrat.mean()\n",
    "mean_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Q_LF'] = [float(i) for i in df_combined['Q_LF'].values]\n",
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.Q_GC=df_combined.Q_GC.fillna(df_combined.Q_LF*mean_rat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.isnan(df_combined.Q_GC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGC_monthly = dfGC.resample('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGC_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGC_monthly.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
